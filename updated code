
import numpy as np #for math
import pandas as pd #for tables/CSV
import matplotlib.pyplot as plt #for plots
from pathlib import Path #for file paths

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 0) constants
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
DATA_CSV = Path("student_scores_integer.csv")
OUT_DIR = Path("./student_lr_outputs")
OUT_DIR.mkdir(parents=True, exist_ok=True)

# Hyperparameters
ALPHA = 0.05       # learning rate
EPOCHS = 2000      # gradient descent steps
THETA_INITIAL = "ones"  # "zeros" or "ones"

# Random seed for dataset generation (deterministic)
SEED = 123

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 1) make sure dataset exists
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
if not DATA_CSV.exists(): #if the CSV is not in the folder, generate it
    #create 1000 rows of random numbers for study_hours and attendence_percent
    rng = np.random.default_rng(SEED)
    n = 1000
    study_hours = np.clip(np.round(rng.normal(10, 4, n)), 0, 30).astype(int)       # 0..30
    attendance_percent = np.clip(np.round(rng.normal(90, 8, n)), 50, 100).astype(int)  # 50..100
    noise = np.round(rng.normal(0, 6, n)).astype(int) #to make the data more realistic

    # Score is integer 0..100
    score = 25 + 3*study_hours + 0.4*attendance_percent + noise
    score = np.clip(np.round(score), 0, 100).astype(int)

    df = pd.DataFrame({
        "StudyHours": study_hours,
        "AttendancePercent": attendance_percent,
        "Score": score
    })
    df.to_csv(DATA_CSV, index=False)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 2) functions for linear regression
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
def feature_scale(X: np.ndarray):
    """Return z-scored features, plus (mu, sigma)."""
    mu = X.mean(axis=0)
    sigma = X.std(axis=0, ddof=0)
    Xs = (X - mu) / sigma
    return Xs, mu, sigma

def add_intercept(X: np.ndarray): #adds a leading column of 1s so theta0 is learned
    import numpy as np
    return np.c_[np.ones((X.shape[0], 1)), X]

def hypothesis(X: np.ndarray, theta: np.ndarray):
    return X @ theta

def cost(X: np.ndarray, y: np.ndarray, theta: np.ndarray): # J(θ)= (1/2m) times summation of (y hat−y)^2
    m = len(y)
    top_part = hypothesis(X, theta) - y
    return (top_part @ top_part) / (2*m)

def gradient_descent(X: np.ndarray, y: np.ndarray, theta_init: np.ndarray, alpha: float, epochs: int):
    theta = theta_init.copy()
    m = len(y)
    J_hist = []
    theta_hist = []
    for t in range(epochs):
        preds = hypothesis(X, theta)
        grad = (X.T @ (preds - y)) / m
        theta -= alpha * grad
        J_hist.append(cost(X, y, theta))
        theta_hist.append(theta.copy())
    return theta, np.array(J_hist), np.array(theta_hist)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 3) data & prepare features
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
data = pd.read_csv(DATA_CSV)
X_raw = data[["StudyHours", "AttendancePercent"]].to_numpy()
y = data["Score"].to_numpy()

X_scaled, mu, sigma = feature_scale(X_raw)
X = add_intercept(X_scaled)

# Initialize theta
if THETA_INITIAL == "ones":
    theta0 = np.ones(X.shape[1])     # [θ0, θ1, θ2]
else:
    theta0 = np.zeros(X.shape[1])

start_cost = cost(X, y, theta0)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 4) training
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
theta_final, J_hist, theta_hist = gradient_descent(X, y, theta0, ALPHA, EPOCHS)
final_cost = J_hist[-1]

# Convert to original (unscaled) units:
# If h = θ0 + θ1*z1 + θ2*z2 with z = (x - mu)/sigma,
# then: b = θ0 - sum_i (θi * mu_i / sigma_i), wi = θi / sigma_i
b_orig = theta_final[0] - (theta_final[1] * mu[0] / sigma[0] + theta_final[2] * mu[1] / sigma[1])
w1_orig = theta_final[1] / sigma[0]  # points per extra StudyHour
w2_orig = theta_final[2] / sigma[1]  # points per +1% attendance

# R^2
y_pred = hypothesis(X, theta_final)
ss_res = np.sum((y - y_pred)**2)
ss_tot = np.sum((y - y.mean())**2)
r2 = 1 - ss_res/ss_tot

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 5) print stats
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
stats_text = f"""
Linear Regression Project — Student Score vs Study Hours & Attendance

Starting values of the parameters (theta): {theta0}
Starting values of the hyperparameters: alpha = {ALPHA}, epochs = {EPOCHS}
Starting value of the cost: {start_cost:.4f}

Value of the parameters at convergence (scaled space): {theta_final}
Equivalent parameters in original units:
  Intercept (b): {b_orig:.4f}
  StudyHours weight: {w1_orig:.4f} points per hour
  AttendancePercent weight: {w2_orig:.4f} points per 1%

Final value of the cost: {final_cost:.4f}
R^2 on full dataset: {r2:.4f}
""".strip()

print(stats_text)
with open(OUT_DIR / "training_stats.txt", "w") as f:
    f.write(stats_text + "\n")

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 6)plots
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 6a) Cost history
plt.figure()
plt.plot(np.arange(len(J_hist)), J_hist)
plt.xlabel("Iteration")
plt.ylabel("Cost J(θ)")
plt.title("Training Cost vs Iteration")
plt.tight_layout()
plt.savefig(OUT_DIR / "cost_history.png")
plt.close()


# 6b) Actual vs Predicted
plt.figure()
plt.scatter(y, y_pred)
plt.xlabel("Actual Score")
plt.ylabel("Predicted Score")
plt.title("Actual vs Predicted")
plt.tight_layout()
plt.savefig(OUT_DIR / "actual_vs_pred.png")
plt.close()


# 6c) Hypothesis (y) vs theta (x) — one plot per parameter

# choose ONE fixed input so hypothesis is a single number per theta snapshot.
# pick a non-mean point so θ1/θ2 actually matter (z1=+1, z2=-0.5)
z1_star = 1.0     # 1 std above mean StudyHours
z2_star = -0.5    # 0.5 std below mean Attendance

# hypothesis at a fixed point x
h_hist = theta_hist[:, 0] + z1_star*theta_hist[:, 1] + z2_star*theta_hist[:, 2]

# θ0 plot
plt.figure()
plt.plot(theta_hist[:, 0], h_hist)
plt.xlabel(r"$\theta_0$ (bias)")
plt.ylabel(r"hypothesis  (predicted at fixed x)")
plt.title(r"Hypothesis vs $\theta_0$")
plt.tight_layout()
plt.savefig(OUT_DIR / "hypothesis_vs_theta0.png")
plt.show()

# θ1 plot
plt.figure()
plt.plot(theta_hist[:, 1], h_hist)
plt.xlabel(r"$\theta_1$ (StudyHours coef, scaled)")
plt.ylabel(r"hypothesis")
plt.title(r"Hypothesis vs $\theta_1$")
plt.tight_layout()
plt.savefig(OUT_DIR / "hypothesis_vs_theta1.png")
plt.show()

# θ2 plot
plt.figure()
plt.plot(theta_hist[:, 2], h_hist)
plt.xlabel(r"$\theta_2$ (Attendance coef, scaled)")
plt.ylabel(r"hypothesis")
plt.title(r"Hypothesis vs $\theta_2$")
plt.tight_layout()
plt.savefig(OUT_DIR / "hypothesis_vs_theta2.png")
plt.show()

